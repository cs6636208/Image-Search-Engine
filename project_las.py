# -*- coding: utf-8 -*-
"""Project@LAS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vT9diNY7faWfT7xcR2kEtx3EP6vOMFAz
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
import numpy as np
import os
from PIL import Image
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist

from google.colab import drive
drive.mount('/content/drive')

mm = load_model('/content/drive/MyDrive/ProjectML-@LAS/resnet50_similarity_model_full.h5')

BASE_DIR = '/content/drive/MyDrive/ProjectML-@LAS/ProjectML-@LAS/Google Images'

TRAIN_DIR = os.path.join(BASE_DIR, 'train')
VAL_DIR = os.path.join(BASE_DIR, 'val')
TEST_EVAL_DIR = os.path.join(BASE_DIR, 'test', 'test_')

IMAGE_SIZE = (224, 224)
BATCH_SIZE = 128
NUM_EPOCHS = 20
LEARNING_RATE = 0.0001

print(f"Directory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Training: {TRAIN_DIR}")
print(f"Directory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Testing/Evaluation: {TEST_EVAL_DIR}")

# @title 3.1 ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

validation_generator = val_test_datagen.flow_from_directory(
    VAL_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_generator = val_test_datagen.flow_from_directory(
    TEST_EVAL_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

NUM_CLASSES = train_generator.num_classes
print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {NUM_CLASSES}")
print(f"‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™: {train_generator.class_indices}")

base_model = ResNet50V2(
    weights='imagenet',   # ‡πÉ‡∏ä‡πâ Weights ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß
    include_top=False,   # ‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° Layer Output ‡πÄ‡∏î‡∏¥‡∏°
    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)
)

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(NUM_CLASSES, activation='softmax') # 18 node outputs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 18 ‡∏Ñ‡∏•‡∏≤‡∏™
])

base_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(224,224,3))
x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)
x = tf.keras.layers.Dense(512, activation='relu')(x)
x = tf.keras.layers.Dropout(0.5)(x)
outputs = tf.keras.layers.Dense(18, activation='softmax')(x)
model = tf.keras.Model(inputs=base_model.input, outputs=outputs)

model.save("model_retrieval.keras")

from tensorflow.keras.models import load_model

model = load_model('my_retrieval_model_final_atlas.h5', compile=False)
model.summary()

model.compile(
    optimizer=Adam(learning_rate=LEARNING_RATE),
    loss='categorical_csrossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    epochs=NUM_EPOCHS,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // BATCH_SIZE
)

final_val_acc = history.history['val_accuracy'][-1]
print(f"\nValidation Accuracy ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: {final_val_acc:.4f}")

test_generator.reset()

loss, accuracy = model.evaluate(test_generator,
                                steps=test_generator.samples // BATCH_SIZE + 1,
                                verbose=1)

print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

model.save('/content/drive/MyDrive/ProjectML-@LAS/resnet50_similarity_model_full.h5', include_optimizer=False)

predictions = model.predict(test_generator, steps=test_generator.samples // BATCH_SIZE + 1)
predicted_classes = tf.argmax(predictions, axis=1)

true_classes = test_generator.classes
label_map = {v: k for k, v in train_generator.class_indices.items()}

for i in range(10):
    predicted_label = label_map[predicted_classes.numpy()[i]]
    true_label = label_map[true_classes[i]]
    result = "‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á" if predicted_classes.numpy()[i] == true_classes[i] else "‡∏ú‡∏¥‡∏î"
    print(f"‡πÑ‡∏ü‡∏•‡πå: {test_generator.filenames[i]} ------ predict: {predicted_label} ----|---- actual: {true_label} ({result})")

SINGLE_IMAGE_PATH = '/content/img.jpg'

import numpy as np
from tensorflow.keras.preprocessing import image
from PIL import Image

IMAGE_SIZE = (224, 224)
try:
    img = image.load_img(SINGLE_IMAGE_PATH, target_size=IMAGE_SIZE)
    img_array = image.img_to_array(img)

    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0

    predictions = model.predict(img_array)

    predicted_class_index = np.argmax(predictions[0])
    confidence = np.max(predictions[0])

    label_map = {v: k for k, v in train_generator.class_indices.items()}
    predicted_label = label_map[predicted_class_index]

    print(f"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà: {predicted_label}")
    print(f"‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {confidence * 100:.2f}%")

except FileNotFoundError:
    print(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà Path: {SINGLE_IMAGE_PATH}")
except NameError:
    print("‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ 'model' ‡∏´‡∏£‡∏∑‡∏≠ 'train_generator' ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô Cell 4 ‡πÅ‡∏•‡∏∞ Cell 3 ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
except Exception as e:
    print(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {e}")

from tensorflow.keras.models import Sequential
import numpy as np

feature_extractor = Sequential(model.layers[:-2])
feature_extractor.build((None, IMAGE_SIZE[0], IMAGE_SIZE[1], 3))

import os
from tqdm.notebook import tqdm
import numpy as np

train_generator.reset()
all_features = []
all_paths = []

num_steps = train_generator.samples // BATCH_SIZE + 1

for i in tqdm(range(num_steps), desc="Building DB"):
    x, y = next(train_generator)
    features = feature_extractor.predict_on_batch(x)
    all_features.append(features)

    current_index = i * BATCH_SIZE
    current_paths = [os.path.join(train_generator.directory, path) for path in train_generator.filenames[current_index : current_index + len(x)]]
    all_paths.extend(current_paths)

all_features = np.concatenate(all_features)
print(f"\n‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Feature: {all_features.shape[0]}")

np.save('/content/drive/MyDrive/ProjectML-@LAS/features.npy', all_features)
np.save('/content/drive/MyDrive/ProjectML-@LAS/paths.npy', all_paths)

from scipy.spatial.distance import cdist
from PIL import Image
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import os

def predict_and_find_similar(input_path, num_results=5):

    img = image.load_img(input_path, target_size=IMAGE_SIZE)
    img_prepped = np.expand_dims(image.img_to_array(img), axis=0) / 255.0

    # 1. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™
    predictions_proba = model.predict(img_prepped, verbose=0)
    predicted_class_index = np.argmax(predictions_proba[0])
    label_map = {v: k for k, v in train_generator.class_indices.items()}
    predicted_label = label_map[predicted_class_index]
    confidence = np.max(predictions_proba[0])
    print(f"Predict: {predicted_label} Confidence: {confidence * 100:.2f}%")

    # 2. ‡∏Å‡∏£‡∏≠‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Features
    all_classes_from_path = [os.path.basename(os.path.dirname(p)) for p in all_paths]
    filtered_indices = [i for i, c in enumerate(all_classes_from_path) if c == predicted_label]
    filtered_features = all_features[filtered_indices]
    filtered_paths = [all_paths[i] for i in filtered_indices]

    # 3. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á
    input_feature = feature_extractor.predict_on_batch(img_prepped)
    distances = cdist(input_feature, filtered_features, metric='euclidean')[0] # <--- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô Euclidean

    similar_indices = np.argsort(distances)[:num_results]
    final_results = [(filtered_paths[i], distances[i]) for i in similar_indices]


    num_columns = num_results + 1 # 1 Query + 5 Results = 6 ‡∏ä‡πà‡∏≠‡∏á

    plt.figure(figsize=(18, 6))

    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ Query (‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà 1)
    plt.subplot(1, num_columns, 1)
    plt.imshow(img)
    plt.title(f"1. Query (TEST)\n{predicted_label}")
    plt.axis('off')

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å (‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà 2 - 6)
    for i, (path, dist) in enumerate(final_results):
        plt.subplot(1, num_columns, i + 2) # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà 2
        sim_img = Image.open(path)

        source_folder = "TRAIN/VAL"
        if "test" in path.lower():
             source_folder = "TEST"

        plt.imshow(sim_img)
        plt.title(f"Rank {i+1} ({source_folder})\nDist: {dist:.4f}")
        plt.axis('off')

    plt.tight_layout()
    plt.show()

import json

class_indices = train_generator.class_indices
with open("class_indices.json", "w") as f:
    json.dump(class_indices, f)

# @title 8.1 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å test
INDEX_TO_TEST = 9
test_generator.reset()
try:
    file_name_to_test = test_generator.filenames[INDEX_TO_TEST]
    test_sample_path = os.path.join(TEST_EVAL_DIR, file_name_to_test)
    predict_and_find_similar(test_sample_path, num_results=5)
except Exception as e:
    print(f"{e}")

MY_UPLOADED_IMAGE_PATH = '/content/img.jpg'

# @title 8.2 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ upload
if os.path.exists(MY_UPLOADED_IMAGE_PATH):
    predict_and_find_similar(MY_UPLOADED_IMAGE_PATH, num_results=5)
else:
    print(f"\n‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {MY_UPLOADED_IMAGE_PATH}")

import os

SAVE_DIR = '/content/drive/MyDrive/ProjectML-@LAS/ProjectML-@LAS/Google Images'
MODEL_FILENAME = 'my_retrieval_model_final_atlas.h5'
FULL_SAVE_PATH = os.path.join(SAVE_DIR, MODEL_FILENAME)

model.save(FULL_SAVE_PATH)

print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: {FULL_SAVE_PATH}")

import numpy as np
import os
SAVE_DIR = '/content/drive/MyDrive/ProjectML-@LAS/'
np.save(os.path.join(SAVE_DIR, 'all_features.npy'), all_features)

import numpy as np
import os
SAVE_DIR = '/content/drive/MyDrive/ProjectML-@LAS/'
np.save(os.path.join(SAVE_DIR, 'all_paths.npy'), all_paths, allow_pickle=True)

MODEL_SAVE_PATH = '/content/drive/MyDrive/ProjectML-@LAS/my_retrieval_model_final_atlas.keras'
model.save(MODEL_SAVE_PATH)
print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: {MODEL_SAVE_PATH}")

base_model_to_save = model.layers[0]

WEIGHTS_SAVE_PATH = '/content/drive/MyDrive/ProjectML-@LAS/resnet_weights.weights.h5'
base_model_to_save.save_weights(WEIGHTS_SAVE_PATH)

print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: {WEIGHTS_SAVE_PATH}")

import numpy as np

raw_weights = model.layers[0].get_weights()

WEIGHTS_SAVE_PATH = '/content/drive/MyDrive/ProjectML-@LAS/resnet_raw_weights_fixed.npy' # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå

np.save(WEIGHTS_SAVE_PATH, np.array(raw_weights, dtype=object), allow_pickle=True)

print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏î‡∏¥‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: {WEIGHTS_SAVE_PATH}")

import json

class_indices = train_generator.class_indices
with open('class_indices.json', 'w') as f:
    json.dump(class_indices, f)
print("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å class_indices.json ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

import numpy as np
import json
import os
# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß: model, train_generator, all_features, all_paths

# 1. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Model
model.save('my_model.h5')
print("‚úÖ 1. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å my_model.h5 ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

# 2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Label Map (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Streamlit)
class_indices = train_generator.class_indices
# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô Class Name (string) : Index (int)
with open('class_indices.json', 'w') as f:
    json.dump(class_indices, f)
print("‚úÖ 2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å class_indices.json ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

# 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Features
np.save('all_features.npy', all_features)
print(f"‚úÖ 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å all_features.npy ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ({all_features.shape})")

# 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Paths ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Placeholder (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å!)
# BASE_DIR ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠: /content/drive/MyDrive/ProjectML-@LAS/Google Images
# ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á Google Drive ‡∏î‡πâ‡∏ß‡∏¢ PLACEHOLDER_PREFIX/

# ‡πÉ‡∏ä‡πâ BASE_DIR ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô /content/drive/MyDrive/ProjectML-@LAS
drive_path_prefix_to_remove = os.path.dirname(BASE_DIR)

paths_for_app = []

for p in all_paths:
    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Path ‡πÉ‡∏ô Drive ‡πÄ‡∏õ‡πá‡∏ô Placeholder
    # ‡πÄ‡∏ä‡πà‡∏ô /content/drive/MyDrive/ProjectML-@LAS/Google Images/train/ClassX/img.jpg
    # ‡∏à‡∏∞‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô PLACEHOLDER_PREFIX/Google Images/train/ClassX/img.jpg
    p_relative = p.replace(drive_path_prefix_to_remove, 'PLACEHOLDER_PREFIX')
    paths_for_app.append(p_relative)

with open('all_paths.txt', 'w') as f:
    for item in paths_for_app:
        f.write("%s\n" % item)

print("‚úÖ 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å all_paths.txt ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ (‡πÉ‡∏ä‡πâ Placeholder)")

# ‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô Colab
# ------------------------------------
# 1. ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Keras API ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
import keras
from tensorflow.keras.models import load_model

# 2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ save_format='h5'
# ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
# ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô 'my_model_v2.h5'
model.save('my_model_v2.h5', save_format='h5')

print("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠ my_model_v2.h5")

# ‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå .npy ‡πÅ‡∏•‡∏∞ .json ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏î‡πâ‡∏ß‡∏¢
# ... (‡πÇ‡∏Ñ‡πâ‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å all_features.npy, all_paths.txt, class_indices.json)
# ------------------------------------

# ‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô Colab (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Keras 3 ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞)
# ----------------------------------------------------------------------
import tensorflow as tf
import keras
import os
import shutil # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß

# 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà (‡πÉ‡∏ä‡πâ .keras ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
# ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà Keras 3 ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏•‡∏∞‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤ .h5
final_keras_path = 'final_working_model.keras'

# 2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (Keras 3 ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö .keras ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
# ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ñ‡∏¢‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏ß‡∏£‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô
if os.path.exists(final_keras_path):
    os.remove(final_keras_path)

model.save(final_keras_path)

print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠: {final_keras_path}")

# 3. ‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
if os.path.isdir('temp_model_tf'):
    shutil.rmtree('temp_model_tf')

# 4. ‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå .npy ‡πÅ‡∏•‡∏∞ .json ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏î‡πâ‡∏ß‡∏¢
# ... (‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏Ñ‡πâ‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å all_features.npy, all_paths.txt, class_indices.json ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Cell ‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏±‡∏ô‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß)
# ----------------------------------------------------------------------

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Colab ‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß

# 1. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏Å
model.save('my_image_classifier_model.h5') # ‡∏´‡∏£‡∏∑‡∏≠ .keras
print("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡πâ‡∏ß")

# 2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ï‡∏±‡∏ß‡∏™‡∏Å‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ (Feature Extractor)
feature_extractor.save('my_feature_extractor_model.h5')
print("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Feature Extractor ‡πÅ‡∏•‡πâ‡∏ß")

# 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Features ‡πÅ‡∏•‡∏∞ Paths
import numpy as np
import pickle

np.save('all_features.npy', all_features)
with open('all_paths.pkl', 'wb') as f:
    pickle.dump(all_paths, f)
print("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Features ‡πÅ‡∏•‡∏∞ Paths ‡πÅ‡∏•‡πâ‡∏ß")

# 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Label Map
import json
with open('class_indices.json', 'w') as f:
    json.dump(train_generator.class_indices, f)
print("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Class Indices ‡πÅ‡∏•‡πâ‡∏ß")

from tensorflow.keras.models import load_model

SAVE_DIR = '/content/drive/MyDrive/ProjectML-@LAS/ProjectML-@LAS'
MODEL_FILENAME = 'my_retrieval_model_final_atlas.h5'
FULL_SAVE_PATH = os.path.join(SAVE_DIR, MODEL_FILENAME)

model = load_model(FULL_SAVE_PATH)
print("‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚úÖ")

SAVE_DIR = '/content/drive/MyDrive/ProjectML-@LAS/ProjectML-@LAS'
MODEL_PATH = os.path.join(SAVE_DIR, 'my_retrieval_model_final_atlas.h5')

model = load_model(MODEL_PATH)
model.summary()
# all_features = np.load(os.path.join(SAVE_DIR, 'all_features.npy'))
# all_paths = np.load(os.path.join(SAVE_DIR, 'all_paths.npy'), allow_pickle=True)

# print(f"all_features shape: {all_features.shape}")
# print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô path: {len(all_paths)}")

IMAGE_SIZE = (224, 224)
feature_extractor = Sequential(model.layers[:-2])
feature_extractor.build((None, IMAGE_SIZE[0], IMAGE_SIZE[1], 3))

def predict_and_find_similar(input_path, num_results=5):
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏†‡∏≤‡∏û input
    img = image.load_img(input_path, target_size=IMAGE_SIZE)
    img_prepped = np.expand_dims(image.img_to_array(img), axis=0) / 255.0

    # 1. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™
    predictions_proba = model.predict(img_prepped, verbose=0)
    predicted_class_index = np.argmax(predictions_proba[0])
    confidence = np.max(predictions_proba[0])
    print(f"Predict class index: {predicted_class_index}, Confidence: {confidence * 100:.2f}%")

    # 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì feature ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û input
    input_feature = feature_extractor.predict_on_batch(img_prepped)

    # 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á Euclidean ‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    distances = cdist(input_feature, all_features, metric='euclidean')[0]
    similar_indices = np.argsort(distances)[:num_results]

    # 4. ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    plt.figure(figsize=(18, 6))
    plt.subplot(1, num_results + 1, 1)
    plt.imshow(img)
    plt.title("Query Image")
    plt.axis('off')

    for i, idx in enumerate(similar_indices):
        sim_img = Image.open(all_paths[idx])
        plt.subplot(1, num_results + 1, i + 2)
        plt.imshow(sim_img)
        plt.title(f"Rank {i+1}\nDist: {distances[idx]:.4f}")
        plt.axis('off')

    plt.tight_layout()
    plt.show()

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from tensorflow.keras.preprocessing import image
from scipy.spatial.distance import cdist

def predict_and_find_similar(input_path, num_results=5):
    # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå input ---
    if not os.path.exists(input_path):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {input_path}")
        return

    # --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏†‡∏≤‡∏û input ---
    img = image.load_img(input_path, target_size=IMAGE_SIZE)
    img_prepped = np.expand_dims(image.img_to_array(img), axis=0) / 255.0

    # --- 1. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™ ---
    predictions_proba = model.predict(img_prepped, verbose=0)
    predicted_class_index = np.argmax(predictions_proba[0])
    confidence = np.max(predictions_proba[0])
    print(f"‚úÖ Predict class index: {predicted_class_index}, Confidence: {confidence * 100:.2f}%")

    # --- 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì feature ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û input ---
    input_feature = feature_extractor.predict_on_batch(img_prepped)

    # --- 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á Euclidean ‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ---
    distances = cdist(input_feature, all_features, metric='euclidean')[0]
    similar_indices = np.argsort(distances)[:num_results]

    # --- 4. ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---
    plt.figure(figsize=(18, 6))
    plt.subplot(1, num_results + 1, 1)
    plt.imshow(img)
    plt.title("Query Image")
    plt.axis('off')

    shown = 0
    for idx in similar_indices:
        path = str(all_paths[idx])  # ‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô string ‡∏õ‡∏Å‡∏ï‡∏¥
        if not os.path.exists(path):
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {path}")
            continue

        try:
            sim_img = Image.open(path)
        except Exception as e:
            print(f"‚ö†Ô∏è ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {path} ({e})")
            continue

        shown += 1
        plt.subplot(1, num_results + 1, shown + 1)
        plt.imshow(sim_img)
        plt.title(f"Rank {shown}\nDist: {distances[idx]:.4f}")
        plt.axis('off')

        if shown >= num_results:
            break

    if shown == 0:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢")
    else:
        plt.tight_layout()
        plt.show()

"""### ***The Last Of Process Project***"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import load_model, Model
from tensorflow.keras.applications.resnet_v2 import preprocess_input
from tensorflow.keras.utils import load_img, img_to_array
import numpy as np
import os
from PIL import Image, ImageFile
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist
from google.colab import drive
from tqdm import tqdm

drive.mount('/content/drive', force_remount=True)

SAVE_DIR = '/content/drive/MyDrive/ProjectML-@LAS/ProjectML-@LAS/'
MODEL_PATH = os.path.join(SAVE_DIR, 'my_retrieval_model_final_atlas.h5')
BASE_DIR = os.path.join(SAVE_DIR, 'Google Images')

TRAIN_DIR = os.path.join(BASE_DIR, 'train')
VAL_DIR = os.path.join(BASE_DIR, 'val')
TEST_DIR = os.path.join(BASE_DIR, 'test', 'test_')

IMAGE_SIZE = (224, 224)
BATCH_SIZE = 128
ImageFile.LOAD_TRUNCATED_IMAGES = True

model = load_model(MODEL_PATH, compile=False)

target_layer_name = None
for layer in model.layers:
    if "global_average_pooling" in layer.name:
        target_layer_name = layer.name
        break

if target_layer_name is None:
    raise ValueError("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå global_average_pooling ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•")

inp = tf.keras.layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
x = inp
for layer in model.layers:
    x = layer(x)
    if layer.name == target_layer_name:
        break
feature_extractor = Model(inputs=inp, outputs=x)
print("‚úÖ Feature extractor ready! Output shape:", feature_extractor.output_shape)

train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'
)
label_map = {v: k for k, v in train_generator.class_indices.items()}

def build_feature_database(base_dirs, output_dir):
    all_features, all_paths = [], []

    for base_dir in base_dirs:
        print(f"\nüìÇ Processing folder: {base_dir}")
        for root, _, files in os.walk(base_dir):
            for file in tqdm(files, desc=os.path.basename(root)):
                if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    img_path = os.path.join(root, file)
                    try:
                        img = load_img(img_path, target_size=IMAGE_SIZE)
                        img_array = np.expand_dims(img_to_array(img), axis=0)
                        img_array = preprocess_input(img_array)
                        feature = feature_extractor.predict(img_array, verbose=0)
                        all_features.append(feature.flatten())
                        all_paths.append(img_path)
                    except Exception as e:
                        print(f"‚ö†Ô∏è Skip: {img_path} ({e})")

    np.save(os.path.join(output_dir, 'all_features.npy'), np.array(all_features))
    np.save(os.path.join(output_dir, 'all_paths.npy'), np.array(all_paths))
    print("\n‚úÖ Features database rebuilt successfully!")
    print(f"Total: {len(all_paths)} images | Shape: {np.array(all_features).shape}")

# üß© ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà ‡πÉ‡∏´‡πâ uncomment
build_feature_database([TRAIN_DIR, VAL_DIR, TEST_DIR], SAVE_DIR)

all_features = np.load(os.path.join(SAVE_DIR, 'all_features.npy'))
all_paths = np.load(os.path.join(SAVE_DIR, 'all_paths.npy'), allow_pickle=True)
print("üì¶ Loaded feature DB:", all_features.shape)

def predict_and_find_similar(input_path, num_results=5, batch_size=128):
    img = load_img(input_path, target_size=IMAGE_SIZE)
    img_prepped = np.expand_dims(img_to_array(img), axis=0)
    img_prepped = preprocess_input(img_prepped)

    predictions_proba = model.predict(img_prepped, verbose=0)
    predicted_class_index = np.argmax(predictions_proba[0])
    predicted_label = label_map[predicted_class_index]
    confidence = np.max(predictions_proba[0])
    print(f"üîç Predict: {predicted_label} | Confidence: {confidence * 100:.2f}%")

    all_classes_from_path = [os.path.basename(os.path.dirname(p)) for p in all_paths]
    filtered_indices = [i for i, c in enumerate(all_classes_from_path) if c == predicted_label]
    filtered_features = all_features[filtered_indices]
    filtered_paths = [str(all_paths[i]) for i in filtered_indices]

    query_feature_full = feature_extractor.predict(img_prepped, verbose=0).flatten()

    input_feature = query_feature_full[:filtered_features.shape[1]]

    distances = []
    num_batches = int(np.ceil(len(filtered_features) / batch_size))
    for i in tqdm(range(num_batches), desc="Distances (batches)"):
        start = i * batch_size
        end = min((i + 1) * batch_size, len(filtered_features))
        batch_features = filtered_features[start:end]
        batch_dist = np.linalg.norm(batch_features - input_feature, axis=1)
        distances.extend(batch_dist)
    distances = np.array(distances)

    similar_indices = np.argsort(distances)[:num_results]
    final_results = [(filtered_paths[i], distances[i]) for i in similar_indices]

    num_columns = num_results + 1
    plt.figure(figsize=(18, 6))

    plt.subplot(1, num_columns, 1)
    plt.imshow(img)
    plt.title(f"Query\n({predicted_label})")
    plt.axis('off')

    for i, (path, dist) in enumerate(final_results):
        plt.subplot(1, num_columns, i + 2)
        sim_img = Image.open(path)
        plt.imshow(sim_img)
        plt.title(f"Rank {i+1}\nDist: {dist:.4f}")
        plt.axis('off')

    plt.tight_layout()
    plt.show()


MY_QUERY_IMAGE = '/content/drive/MyDrive/ProjectML-@LAS/ProjectML-@LAS/Google Images/test/test_/Pyramids Of Giza - Egypt/180.jpg'
# MY_QUERY_IMAGE = '/content/bg-mobile.jpg'
# MY_QUERY_IMAGE = '/content/kmutnb.png'

if os.path.exists(MY_QUERY_IMAGE):
    predict_and_find_similar(MY_QUERY_IMAGE, num_results=5, batch_size=128)
else:
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {MY_QUERY_IMAGE}")