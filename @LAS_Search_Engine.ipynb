{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J27iOSZs-ECz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image, ImageFile\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cdist\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "SAVE_DIR = '/content/drive/MyDrive/ProjectML-@LAS/ProjectML-@LAS/'\n",
        "MODEL_PATH = os.path.join(SAVE_DIR, 'my_retrieval_model_final_atlas.h5')\n",
        "BASE_DIR = os.path.join(SAVE_DIR, 'Google Images')\n",
        "\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
        "VAL_DIR = os.path.join(BASE_DIR, 'val')\n",
        "TEST_DIR = os.path.join(BASE_DIR, 'test', 'test_')\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 128\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "model = load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "target_layer_name = None\n",
        "for layer in model.layers:\n",
        "    if \"global_average_pooling\" in layer.name:\n",
        "        target_layer_name = layer.name\n",
        "        break\n",
        "\n",
        "if target_layer_name is None:\n",
        "    raise ValueError(\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå global_average_pooling ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•\")\n",
        "\n",
        "inp = tf.keras.layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "x = inp\n",
        "for layer in model.layers:\n",
        "    x = layer(x)\n",
        "    if layer.name == target_layer_name:\n",
        "        break\n",
        "feature_extractor = Model(inputs=inp, outputs=x)\n",
        "print(\"‚úÖ Feature extractor ready! Output shape:\", feature_extractor.output_shape)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\n",
        ")\n",
        "label_map = {v: k for k, v in train_generator.class_indices.items()}\n",
        "\n",
        "def build_feature_database(base_dirs, output_dir):\n",
        "    all_features, all_paths = [], []\n",
        "\n",
        "    for base_dir in base_dirs:\n",
        "        print(f\"\\nüìÇ Processing folder: {base_dir}\")\n",
        "        for root, _, files in os.walk(base_dir):\n",
        "            for file in tqdm(files, desc=os.path.basename(root)):\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    img_path = os.path.join(root, file)\n",
        "                    try:\n",
        "                        img = load_img(img_path, target_size=IMAGE_SIZE)\n",
        "                        img_array = np.expand_dims(img_to_array(img), axis=0)\n",
        "                        img_array = preprocess_input(img_array)\n",
        "                        feature = feature_extractor.predict(img_array, verbose=0)\n",
        "                        all_features.append(feature.flatten())\n",
        "                        all_paths.append(img_path)\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Skip: {img_path} ({e})\")\n",
        "\n",
        "    np.save(os.path.join(output_dir, 'all_features.npy'), np.array(all_features))\n",
        "    np.save(os.path.join(output_dir, 'all_paths.npy'), np.array(all_paths))\n",
        "    print(\"\\n‚úÖ Features database rebuilt successfully!\")\n",
        "    print(f\"Total: {len(all_paths)} images | Shape: {np.array(all_features).shape}\")\n",
        "\n",
        "# üß© ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà ‡πÉ‡∏´‡πâ uncomment\n",
        "build_feature_database([TRAIN_DIR, VAL_DIR, TEST_DIR], SAVE_DIR)\n",
        "\n",
        "all_features = np.load(os.path.join(SAVE_DIR, 'all_features.npy'))\n",
        "all_paths = np.load(os.path.join(SAVE_DIR, 'all_paths.npy'), allow_pickle=True)\n",
        "print(\"üì¶ Loaded feature DB:\", all_features.shape)\n",
        "\n",
        "def predict_and_find_similar(input_path, num_results=5, batch_size=128):\n",
        "    img = load_img(input_path, target_size=IMAGE_SIZE)\n",
        "    img_prepped = np.expand_dims(img_to_array(img), axis=0)\n",
        "    img_prepped = preprocess_input(img_prepped)\n",
        "\n",
        "    predictions_proba = model.predict(img_prepped, verbose=0)\n",
        "    predicted_class_index = np.argmax(predictions_proba[0])\n",
        "    predicted_label = label_map[predicted_class_index]\n",
        "    confidence = np.max(predictions_proba[0])\n",
        "    print(f\"üîç Predict: {predicted_label} | Confidence: {confidence * 100:.2f}%\")\n",
        "\n",
        "    all_classes_from_path = [os.path.basename(os.path.dirname(p)) for p in all_paths]\n",
        "    filtered_indices = [i for i, c in enumerate(all_classes_from_path) if c == predicted_label]\n",
        "    filtered_features = all_features[filtered_indices]\n",
        "    filtered_paths = [str(all_paths[i]) for i in filtered_indices]\n",
        "\n",
        "    query_feature_full = feature_extractor.predict(img_prepped, verbose=0).flatten()\n",
        "\n",
        "    input_feature = query_feature_full[:filtered_features.shape[1]]\n",
        "\n",
        "    distances = []\n",
        "    num_batches = int(np.ceil(len(filtered_features) / batch_size))\n",
        "    for i in tqdm(range(num_batches), desc=\"Distances (batches)\"):\n",
        "        start = i * batch_size\n",
        "        end = min((i + 1) * batch_size, len(filtered_features))\n",
        "        batch_features = filtered_features[start:end]\n",
        "        batch_dist = np.linalg.norm(batch_features - input_feature, axis=1)\n",
        "        distances.extend(batch_dist)\n",
        "    distances = np.array(distances)\n",
        "\n",
        "    similar_indices = np.argsort(distances)[:num_results]\n",
        "    final_results = [(filtered_paths[i], distances[i]) for i in similar_indices]\n",
        "\n",
        "    num_columns = num_results + 1\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    plt.subplot(1, num_columns, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Query\\n({predicted_label})\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    for i, (path, dist) in enumerate(final_results):\n",
        "        plt.subplot(1, num_columns, i + 2)\n",
        "        sim_img = Image.open(path)\n",
        "        plt.imshow(sim_img)\n",
        "        plt.title(f\"Rank {i+1}\\nDist: {dist:.4f}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "MY_QUERY_IMAGE = '/content/drive/MyDrive/ProjectML-@LAS/ProjectML-@LAS/Google Images/test/test_/Pyramids Of Giza - Egypt/180.jpg'\n",
        "# MY_QUERY_IMAGE = '/content/bg-mobile.jpg'\n",
        "# MY_QUERY_IMAGE = '/content/kmutnb.png'\n",
        "\n",
        "if os.path.exists(MY_QUERY_IMAGE):\n",
        "    predict_and_find_similar(MY_QUERY_IMAGE, num_results=5, batch_size=128)\n",
        "else:\n",
        "    print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {MY_QUERY_IMAGE}\")\n"
      ]
    }
  ]
}